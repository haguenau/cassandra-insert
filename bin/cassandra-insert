#! /usr/bin/perl -w
use strict;
require 5.10.0;
use Cassandra::Client;
use Getopt::Long;
use Time::HiRes qw(time sleep);
use JSON;
use FindBin qw($RealBin);
use lib $RealBin . '/../lib';
use BinaryCodec qw(:all);

## Parse config file
my $fconf = $RealBin . '/../conf/cassandra-insert.json';
open(FCONF, $fconf)
  or die "Couldn't open \`$fconf' for reading: $!";
my $conf;
{
    local $/ = undef;
    $conf = from_json <FCONF>;
}
close FCONF;

my @seed_hosts = @{$conf->{nodes} // []};
my $db = $conf->{db};

## Parse command line (overrides conf)
my $table;
my $ttl = 86400;

my $throttle_interval = 100;    # Adjust for pacing after this many inserts
my $throttle_wps = 1000;        # Set writes per second limit

my $def_constants;
my $def_types;
my $is_verbose = 0;
exit 1 unless GetOptions
  (
   'nodes=s' => sub { @seed_hosts = split /,/, $_[1]; },
   'db=s' => \$db,
   'table=s' => \$table,
   'ttl=s' => \$ttl,
   'throttle-wps=s' => \$throttle_wps,
   'const=s' => \$def_constants,
   'header=s' => \$def_types,
   'v|verbose' => \$is_verbose,
  );

my %mustset =
  (
   const => \$def_constants,
   db => \$db,
   header => \$def_types,
   table => \$table,
  );

my $ok = 1;
for my $k (keys %mustset) {
    unless (defined ${$mustset{$k}}) {
        warn "Error: parameter \`$k' is unset.\n";
        $ok = 0;
    }
}
exit 1 unless $ok;

sub identity($) { return shift; }

my %converters =
  (
   'auto' => \&identity,
   'delta-varint-list' => \&BinaryCodec::delta_varint_list_encode,
  );

my @keys = qw(key column1 column2 value);
my %keys = map { $_ => 1 } @keys;

sub check_get_converter($) {
    my $type = shift;
    my $converter = $converters{$type};

    die "No converter for type \`$type'" unless defined $converter;
    return $converter;
}

sub check_key_definable($) {
    my $key = shift;
    die "Bad key \`$key'" unless defined $keys{$key};
}


my %convert = ();
## Parse constants
# fmt: <id>:<type>=<value>{,<id>:<type>=<value>}
my @conststrs = split /,/, $def_constants;
for my $constdef (@conststrs) {
    my ($k, $t, $v) = $constdef =~ /^([a-z0-9-]+):([a-z0-9-]+)=(.*)$/;
    die "Bad constant definition string \`$constdef'" unless defined $v;
    die "Duplicate constant key \`$k'" if defined $convert{$k};
    die "Invalid constant key \`$k'" unless defined $keys{$k};

    my $converter = check_get_converter $t;
    $convert{$k} = { value => $converter->($v) };
}

## Parse header
# fmt: <id>:<type>{,<id>:<type>}
my $column_count;
{
    my @headstrs = split /,/, $def_types;
    $column_count = @headstrs;
    my $i = 0;
    for my $typedef (@headstrs) {
        my ($k, $t) = $typedef =~ /^([a-z0-9-]+):([a-z0-9-]+)$/;
        die "Bad type declaration string \`$typedef'" unless defined $t;
        die "Duplicate data key \`$k'" if defined $convert{$k};
        die "Invalid data key \`$k'" unless defined $keys{$k};

        $convert{$k} = { convert => check_get_converter $t, index => $i++ };
    }
}

## Check that all keys were set
{
    my @missing_keys = ();
    for my $k (sort keys %keys) {
        push @missing_keys, $k unless defined $convert{$k};
    }

    die sprintf "Must set all keys; missing %s",
      join ', ', map {  "\`$_'" } @missing_keys if @missing_keys;
}

my $time_start = time;
my $duration_slept = 0;
sub throttle_sleep($$) {
    my ($wps, $writes_completed) = @_;
    return unless defined $wps or $wps <= 0;

    my $target_duration = $writes_completed / $wps;
    my $target_time = $time_start + $target_duration;
    my $now = time;

    if ($now < $target_time) {
        my $sleep_seconds = $target_time - $now;
        printf STDERR "Sleep %.2f to respect throttling.\n", $sleep_seconds
          if $is_verbose;
        sleep $sleep_seconds;
        $duration_slept += $sleep_seconds;
    }
}

## Insert
my $cass = Cassandra::Client->new
  (
   contact_points => \@seed_hosts,
   keyspace => $db,
  );

$cass->connect;

my $query = sprintf
  'INSERT INTO "%s" (%s) VALUES (?, ?, ?, ?)',
  $table,
  join ', ', @keys;
my $ttl_query = ' USING TTL ?';

$query .= $ttl_query if defined $ttl;

my ($recs_in, $recs_out, $bad_recs, $write_failures) = (0, 0, 0, 0);
while (<STDIN>) {
    ++$recs_in;
    my @data = split /\t/;
    if (@data != $column_count) {
        ++$bad_recs;
        next;
    }

    my @values = ();
    for my $k (@keys) {
        my $entry = $convert{$k};
        my $value;

        if (defined $entry->{value}) {
            $value = $entry->{value};
        } else {
            my $converter = $entry->{convert};
            my $str = $data[$entry->{index}];
            $value = $converter->($str);
        }
        push @values, $value;
    }
    push @values, $ttl if defined $ttl;

    my $ok = eval { $cass->execute($query, \@values); };
    if ($ok) {
        ++$recs_out;
    } else {
        ++$write_failures;
        printf STDERR "FAIL: %s\n", join ', ', $@;
    }

    if (($recs_out % $throttle_interval) == 0) {
        throttle_sleep $throttle_wps, $recs_out;
    }
}

my %metrics =
  (
   recs_in => $recs_in,
   recs_out => $recs_out,
   bad_recs => $bad_recs,
   write_failures => $write_failures,
   seconds_slept => $duration_slept,
   seconds_total => time - $time_start,
   unix_time => int $time_start,
  );

sub as_json($) {
    my $data = shift;
    return to_json($data, { canonical => 1}) . "\n";
}

sub as_kv($) {
    my $data = shift;
    for my $k (keys %$data) {
        printf "%s %s\n", $k, $data->{$k};
    }
}

print as_json \%metrics;
# print as_kv \%metrics;
